"""
å®ä½“æå–å·¥å…·
ä½¿ç”¨å¤§æ¨¡å‹ä»ä¸»æ’­è¯­éŸ³ä¸­æå–ç»“æ„åŒ–çš„å•†å“ä¿¡æ¯ã€ä»·æ ¼å’Œåº“å­˜
"""

import json
import logging
import re
from typing import Optional, Dict, Any
from langchain.tools import tool, ToolRuntime
from coze_coding_dev_sdk import LLMClient
from coze_coding_utils.runtime_ctx.context import new_context
from langchain_core.messages import SystemMessage, HumanMessage

logger = logging.getLogger(__name__)


@tool
def extract_anchor_entities(speech_text: str, runtime: ToolRuntime = None) -> str:
    """
    ä½¿ç”¨å¤§æ¨¡å‹ä»ä¸»æ’­è¯­éŸ³ä¸­æå–å•†å“ä¿¡æ¯ã€ä»·æ ¼å’Œåº“å­˜
    
    ç›¸æ¯”æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿™ä¸ªå·¥å…·å…·æœ‰æ›´å¼ºçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥ï¼š
    - åŒºåˆ†"åŸä»·99ï¼Œç°åœ¨åªè¦19"ä¸­çš„å®é™…å”®ä»·
    - è¯†åˆ«"åº“å­˜å¤§æ¦‚è¿˜æœ‰30ã€40å°"ä¸­çš„æ¨¡ç³Šæ•°é‡
    - æå–"iPhone 15 Pro"è¿™æ ·çš„å¤åˆå•†å“å
    
    å‚æ•°:
        speech_text: ä¸»æ’­è¯´çš„è¯
    
    è¿”å›:
        æå–çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬å•†å“åã€ä»·æ ¼ã€åº“å­˜ã€æ“ä½œæ„å›¾
    """
    ctx = runtime.context if runtime else new_context(method="extract_anchor_entities")
    
    try:
        client = LLMClient(ctx=ctx)
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç›´æ’­è¯­éŸ³å®ä½“æå–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ä¸»æ’­çš„è¯­éŸ³ä¸­å‡†ç¡®æå–å•†å“ä¿¡æ¯ã€ä»·æ ¼å’Œåº“å­˜æ•°é‡ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›æå–ç»“æœï¼š

{
  "product_name": "å•†å“åç§°ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼Œè¿”å›æœ€ä¸»è¦çš„å•†å“ï¼‰",
  "mentioned_price": {
    "value": ä»·æ ¼æ•°å­—,
    "currency": "è´§å¸å•ä½ï¼ˆCNY/USDï¼‰",
    "is_original_price": true/false,
    "is_sale_price": true/false,
    "confidence": "high/medium/low",
    "context": "ä»·æ ¼è¯­å¢ƒè¯´æ˜"
  },
  "mentioned_stock": {
    "value": åº“å­˜æ•°é‡ï¼ˆæ•´æ•°ï¼‰",
    "unit": "å•ä½ï¼ˆä»¶/å°/å¥—ï¼‰",
    "is_estimated": true/false,
    "confidence": "high/medium/low",
    "context": "åº“å­˜è¯­å¢ƒè¯´æ˜"
  },
  "intent": "ä¸»æ’­æ„å›¾ï¼ˆintroduce_product/update_price/update_stock/generalï¼‰",
  "entities": [
    {"type": "product_name", "text": "iPhone 15 Pro", "start": 0, "end": 11},
    {"type": "price", "text": "7999å…ƒ", "value": 7999, "start": 20, "end": 26}
  ],
  "summary": "ç®€çŸ­æ€»ç»“ä¸»æ’­è¯´çš„è¯"
}

æå–è§„åˆ™ï¼š
1. **ä»·æ ¼æå–**ï¼š
   - ä¼˜å…ˆæå–"ç°åœ¨"ã€"åªè¦"ã€"ä»Šå¤©"ç­‰è¯æ±‡åé¢çš„ä»·æ ¼ï¼ˆè¿™æ˜¯å½“å‰å”®ä»·ï¼‰
   - åŒºåˆ†"åŸä»·"å’Œ"ç°ä»·"ï¼Œæ ‡æ³¨ is_original_price å’Œ is_sale_price
   - å¦‚æœæœ‰å¤šä¸ªä»·æ ¼ï¼Œæ ‡è®°æ‰€æœ‰ä»·æ ¼å¹¶æ ‡æ³¨å„è‡ªçš„å«ä¹‰
   - ä»·æ ¼å•ä½é»˜è®¤ä¸ºå…ƒï¼ˆCNYï¼‰

2. **åº“å­˜æå–**ï¼š
   - æå–æ˜ç¡®æ•°å­—ï¼Œå¦‚"åº“å­˜30å°" -> 30
   - å¤„ç†æ¨¡ç³Šè¡¨è¾¾ï¼Œå¦‚"å¤§æ¦‚30ã€40å°" -> 30ï¼ˆå–æœ€å°å€¼ï¼‰
   - æ ‡è®° is_estimated å¦‚æœæ˜¯æ¨¡ç³Šæ•°å­—

3. **å•†å“åæå–**ï¼š
   - ä¼˜å…ˆæå–å®Œæ•´çš„å•†å“å‹å·ï¼Œå¦‚"iPhone 15 Pro 256G"
   - å¦‚æœåªæœ‰å“ç±»åï¼ˆå¦‚"è¿™æ¬¾æ‰‹æœº"ï¼‰ï¼Œproduct_name è®¾ä¸º null

4. **ç½®ä¿¡åº¦**ï¼š
   - high: ä¿¡æ¯æ˜ç¡®ï¼Œæ•°å­—å‡†ç¡®
   - medium: ä¿¡æ¯è¾ƒæ˜ç¡®ï¼Œä½†å¯èƒ½æœ‰æ¨¡ç³Šä¹‹å¤„
   - low: ä¿¡æ¯æ¨¡ç³Šï¼Œä¸ç¡®å®š

5. **æ„å›¾è¯†åˆ«**ï¼š
   - introduce_product: ä»‹ç»æ–°å•†å“
   - update_price: æ›´æ–°ä»·æ ¼ä¿¡æ¯
   - update_stock: æ›´æ–°åº“å­˜ä¿¡æ¯
   - general: ä¸€èˆ¬æ€§æè¿°

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"iPhone 15 Proç°åœ¨åªè¦7999å…ƒï¼Œåº“å­˜è¿˜æœ‰30å°"
è¾“å‡ºï¼š
{
  "product_name": "iPhone 15 Pro",
  "mentioned_price": {"value": 7999, "currency": "CNY", "is_original_price": false, "is_sale_price": true, "confidence": "high", "context": "å½“å‰å”®ä»·"},
  "mentioned_stock": {"value": 30, "unit": "å°", "is_estimated": false, "confidence": "high", "context": "æ˜ç¡®åº“å­˜"},
  "intent": "update_price",
  "summary": "iPhone 15 Proå½“å‰å”®ä»·7999å…ƒï¼Œåº“å­˜30å°"
}

ç¤ºä¾‹2ï¼š
è¾“å…¥ï¼š"åŸä»·999ï¼Œç°åœ¨åªè¦199ï¼ŒæŠ¢ç–¯äº†"
è¾“å‡ºï¼š
{
  "product_name": null,
  "mentioned_price": {"value": 199, "currency": "CNY", "is_original_price": false, "is_sale_price": true, "confidence": "high", "context": "å½“å‰å”®ä»·ï¼ˆå¯¹æ¯”åŸä»·999ï¼‰"},
  "mentioned_stock": null,
  "intent": "update_price",
  "summary": "å•†å“åŸä»·999å…ƒï¼Œç°ä»·199å…ƒ"
}

åªè¿”å›JSONï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ä¸»æ’­è¯´çš„è¯: {speech_text}\n\nè¯·æå–å®ä½“ä¿¡æ¯ã€‚")
        ]
        
        response = client.invoke(
            messages=messages,
            model="doubao-seed-1-6-thinking-250715",
            temperature=0.1
        )
        
        # æå–æ–‡æœ¬å†…å®¹
        content = response.content
        if isinstance(content, list):
            content = " ".join([item.get("text", "") if isinstance(item, dict) else str(item) for item in content])
        
        # å°è¯•è§£æJSON
        try:
            entities = json.loads(content)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result_parts = ["ã€å®ä½“æå–ç»“æœã€‘"]
            result_parts.append(f"åŸè¯: {speech_text}")
            result_parts.append(f"æ„å›¾: {entities.get('intent', 'general')}")
            result_parts.append(f"æ€»ç»“: {entities.get('summary', '')}")
            
            if entities.get('product_name'):
                result_parts.append(f"\nğŸ“¦ å•†å“: {entities['product_name']}")
            
            if entities.get('mentioned_price'):
                price_info = entities['mentioned_price']
                price_label = "åŸä»·" if price_info.get('is_original_price') else "ç°ä»·"
                result_parts.append(f"\nğŸ’° ä»·æ ¼: {price_label} Â¥{price_info['value']} ({price_info['confidence']})")
                result_parts.append(f"   è¯­å¢ƒ: {price_info.get('context', '')}")
            
            if entities.get('mentioned_stock'):
                stock_info = entities['mentioned_stock']
                estimated = "çº¦" if stock_info.get('is_estimated') else ""
                result_parts.append(f"\nğŸ“¦ åº“å­˜: {estimated}{stock_info['value']} {stock_info['unit']} ({stock_info['confidence']})")
                result_parts.append(f"   è¯­å¢ƒ: {stock_info.get('context', '')}")
            
            if entities.get('entities'):
                result_parts.append(f"\nğŸ” æå–çš„å®ä½“:")
                for entity in entities['entities']:
                    result_parts.append(f"   - {entity['type']}: {entity['text']}")
            
            return "\n".join(result_parts)
        
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {str(e)}")
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
            return f"å®ä½“æå–ç»“æœï¼ˆæœªè§£æï¼‰:\n{content}"
    
    except Exception as e:
        logger.error(f"æå–å®ä½“å¤±è´¥: {str(e)}")
        return f"æå–å®ä½“å¤±è´¥: {str(e)}"


@tool
def smart_extract_price(speech_text: str, runtime: ToolRuntime = None) -> str:
    """
    æ™ºèƒ½æå–ä»·æ ¼ï¼ˆä¸“é—¨é’ˆå¯¹ä»·æ ¼æå–ï¼‰
    
    ç›¸æ¯”æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¯ä»¥å‡†ç¡®è¯†åˆ«ï¼š
    - "åŸä»·99ï¼Œç°åœ¨åªè¦19" â†’ æå–19ï¼ˆç°ä»·ï¼‰
    - "ä»Šå¤©ç‰¹ä»·199" â†’ æå–199
    - "å…¨åœº9.9å…ƒèµ·" â†’ æå–9.9
    
    å‚æ•°:
        speech_text: ä¸»æ’­è¯´çš„è¯
    
    è¿”å›:
        æå–çš„ä»·æ ¼åŠç½®ä¿¡åº¦
    """
    ctx = runtime.context if runtime else new_context(method="smart_extract_price")
    
    try:
        # å…ˆå°è¯•æå–å®ä½“
        entity_result = extract_anchor_entities(speech_text=speech_text)
        
        # è§£æç»“æœ
        if "ä»·æ ¼:" in entity_result:
            return entity_result
        
        # å¦‚æœLLMæå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ­£åˆ™æ–¹æ³•
        # åŒ¹é…ï¼šç°ä»·ã€åªè¦ã€ç‰¹ä»·ã€ç­‰å…³é”®è¯åé¢çš„ä»·æ ¼
        patterns = [
            r'(?:ç°åœ¨|åªè¦|ç‰¹ä»·|å”®ä»·|ä»Šå¤©|å½“å‰)\s*(?:æ˜¯)?\s*Â¥?(\d+\.?\d*)',
            r'Â¥?(\d+\.?\d*)\s*(?:å…ƒ|å—é’±)(?!\s*åŸ)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, speech_text)
            if matches:
                # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä»·æ ¼
                price = float(matches[0])
                return f"æå–åˆ°ä»·æ ¼: Â¥{price:.2f} (æ­£åˆ™åŒ¹é…ï¼Œç½®ä¿¡åº¦medium)"
        
        return "æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°æ˜ç¡®çš„ä»·æ ¼ä¿¡æ¯"
    
    except Exception as e:
        logger.error(f"æ™ºèƒ½æå–ä»·æ ¼å¤±è´¥: {str(e)}")
        return f"æå–ä»·æ ¼å¤±è´¥: {str(e)}"


@tool
def smart_extract_stock(speech_text: str, runtime: ToolRuntime = None) -> str:
    """
    æ™ºèƒ½æå–åº“å­˜ï¼ˆä¸“é—¨é’ˆå¯¹åº“å­˜æå–ï¼‰
    
    ç›¸æ¯”æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¯ä»¥å‡†ç¡®è¯†åˆ«ï¼š
    - "åº“å­˜è¿˜æœ‰30å°" â†’ 30
    - "å¤§æ¦‚50ã€60ä¸ª" â†’ 50ï¼ˆå–æœ€å°å€¼ï¼‰
    - "æœ€å100ä»¶" â†’ 100
    
    å‚æ•°:
        speech_text: ä¸»æ’­è¯´çš„è¯
    
    è¿”å›:
        æå–çš„åº“å­˜æ•°é‡åŠç½®ä¿¡åº¦
    """
    ctx = runtime.context if runtime else new_context(method="smart_extract_stock")
    
    try:
        # å…ˆå°è¯•æå–å®ä½“
        entity_result = extract_anchor_entities(speech_text=speech_text)
        
        # è§£æç»“æœ
        if "åº“å­˜:" in entity_result:
            return entity_result
        
        # å¦‚æœLLMæå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ­£åˆ™æ–¹æ³•
        # åŒ¹é…ï¼šåº“å­˜ã€è¿˜æœ‰ã€æœ€åã€ç­‰å…³é”®è¯åé¢çš„æ•°å­—
        patterns = [
            r'(?:åº“å­˜|è¿˜æœ‰|å‰©|æœ€å)\s*(?:æ˜¯)?\s*(\d+)\s*(?:ä»¶|å°|ä¸ª|å¥—|åª)',
            r'(?:ä»…)\s*(\d+)\s*(?:ä»¶|å°|ä¸ª|å¥—)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, speech_text)
            if matches:
                # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„åº“å­˜
                stock = int(matches[0])
                return f"æå–åˆ°åº“å­˜: {stock} ä»¶ (æ­£åˆ™åŒ¹é…ï¼Œç½®ä¿¡åº¦medium)"
        
        return "æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°æ˜ç¡®çš„åº“å­˜ä¿¡æ¯"
    
    except Exception as e:
        logger.error(f"æ™ºèƒ½æå–åº“å­˜å¤±è´¥: {str(e)}")
        return f"æå–åº“å­˜å¤±è´¥: {str(e)}"
