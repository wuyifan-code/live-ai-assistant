"""
è¯­éŸ³äº¤äº’å·¥å…·
TTSè¯­éŸ³è¾“å‡ºã€ä¸ªæ€§åŒ–è¯æœ¯å¼•æ“
"""

import logging
import asyncio
import time
from typing import Optional, Dict, Any, List
from datetime import datetime
from enum import Enum
from dataclasses import dataclass
import os

from coze_coding_dev_sdk import TTSClient
from coze_coding_utils.runtime_ctx.context import new_context

logger = logging.getLogger(__name__)


class VoicePersonality(Enum):
    """è¯­éŸ³äººæ ¼ç±»å‹"""
    PROFESSIONAL = "professional"      # ä¸“ä¸šç†æ€§çš„å‚æ•°ä¸“å®¶
    ENTHUSIASTIC = "enthusiastic"      # çƒ­æƒ…å¹½é»˜çš„ç¦åˆ©å®˜
    CARING = "caring"                  # æ¸©æŸ”ä½“è´´çš„å®¢æœå§å§
    WITTY = "witty"                    # æœºæ™ºé£è¶£çš„å¯¼è´­
    CALM = "calm"                      # æ²‰ç¨³å¤§æ°”çš„å“ç‰Œé¡¾é—®


class LiveStreamMood(Enum):
    """ç›´æ’­é—´æ°›å›´"""
    EXCITING = "exciting"              # çƒ­é—¹å…´å¥‹ï¼ˆä¿ƒé”€ã€ç§’æ€ï¼‰
    RELAXED = "relaxed"                # è½»æ¾æ‚ é—²ï¼ˆæ—¥å¸¸èŠå¤©ï¼‰
    INTENSE = "intense"                # ç´§å¼ æ¿€çƒˆï¼ˆé™æ—¶æŠ¢è´­ï¼‰
    WARM = "warm"                      # æ¸©é¦¨èˆ’é€‚ï¼ˆæƒ…æ„Ÿäº¤æµï¼‰
    SERIOUS = "serious"                # ä¸¥è‚ƒæ­£å¼ï¼ˆæŠ•è¯‰å¤„ç†ï¼‰


@dataclass
class VoiceConfig:
    """è¯­éŸ³é…ç½®"""
    speaker: str
    speech_rate: int = 0
    loudness_rate: int = 0
    style: str = "normal"


# äººæ ¼é…ç½®æ˜ å°„
PERSONALITY_CONFIGS = {
    VoicePersonality.PROFESSIONAL: VoiceConfig(
        speaker="zh_male_dayi_saturn_bigtts",  # å¤§æ¯…ï¼Œä¸“ä¸šç”·å£°
        speech_rate=-10,  # ç¨æ…¢ï¼Œç¨³é‡
        loudness_rate=0,
        style="professional"
    ),
    VoicePersonality.ENTHUSIASTIC: VoiceConfig(
        speaker="zh_female_jitangnv_saturn_bigtts",  # æ¿€æƒ…å¥³å£°
        speech_rate=20,  # å¿«é€Ÿï¼Œæ¿€æƒ…
        loudness_rate=10,
        style="enthusiastic"
    ),
    VoicePersonality.CARING: VoiceConfig(
        speaker="zh_female_meilinvyou_saturn_bigtts",  # æ¸©æŸ”å¥³å‹
        speech_rate=-5,  # ç¨æ…¢ï¼Œæ¸©æŸ”
        loudness_rate=-5,
        style="caring"
    ),
    VoicePersonality.WITTY: VoiceConfig(
        speaker="saturn_zh_female_tiaopigongzhu_tob",  # ä¿çš®å…¬ä¸»
        speech_rate=15,  # ç¨å¿«ï¼Œä¿çš®
        loudness_rate=5,
        style="witty"
    ),
    VoicePersonality.CALM: VoiceConfig(
        speaker="zh_male_ruyayichen_saturn_bigtts",  # å„’é›…ç”·å£°
        speech_rate=-15,  # æ…¢ï¼Œæ²‰ç¨³
        loudness_rate=0,
        style="calm"
    )
}


class PersonalityEngine:
    """ä¸ªæ€§åŒ–è¯æœ¯å¼•æ“"""
    
    def __init__(self, default_personality: VoicePersonality = VoicePersonality.ENTHUSIASTIC):
        """
        å‚æ•°:
            default_personality: é»˜è®¤äººæ ¼
        """
        self.default_personality = default_personality
        self.current_personality = default_personality
        self.mood_history = []
    
    def detect_mood_from_context(
        self,
        danmaku_density: float = 0,
        sentiment_score: float = 0.5,
        has_promotion: bool = False,
        has_complaint: bool = False
    ) -> LiveStreamMood:
        """
        ä»ä¸Šä¸‹æ–‡æ£€æµ‹ç›´æ’­é—´æ°›å›´
        
        å‚æ•°:
            danmaku_density: å¼¹å¹•å¯†åº¦ï¼ˆæ¡/ç§’ï¼‰
            sentiment_score: æƒ…æ„Ÿåˆ†æ•°ï¼ˆ0-1ï¼Œ1ä¸ºæœ€ç§¯æï¼‰
            has_promotion: æ˜¯å¦æœ‰ä¿ƒé”€æ´»åŠ¨
            has_complaint: æ˜¯å¦æœ‰æŠ•è¯‰
        
        è¿”å›:
            æ£€æµ‹åˆ°çš„æ°›å›´
        """
        # æœ‰æŠ•è¯‰ï¼Œä¸¥è‚ƒæ°›å›´
        if has_complaint:
            return LiveStreamMood.SERIOUS
        
        # æœ‰ä¿ƒé”€ä¸”å¼¹å¹•å¯†åº¦é«˜ï¼Œçƒ­é—¹æ°›å›´
        if has_promotion and danmaku_density > 2:
            return LiveStreamMood.EXCITING
        
        # æœ‰ä¿ƒé”€ä½†å¯†åº¦ä¸€èˆ¬ï¼Œç´§å¼ æ°›å›´
        if has_promotion:
            return LiveStreamMood.INTENSE
        
        # å¼¹å¹•å°‘ä¸”æƒ…æ„Ÿç§¯æï¼Œè½»æ¾æ°›å›´
        if danmaku_density < 0.5 and sentiment_score > 0.6:
            return LiveStreamMood.RELAXED
        
        # æƒ…æ„Ÿç§¯æä¸”äº’åŠ¨å¤šï¼Œæ¸©é¦¨æ°›å›´
        if sentiment_score > 0.7 and danmaku_density > 1:
            return LiveStreamMood.WARM
        
        # é»˜è®¤è½»æ¾
        return LiveStreamMood.RELAXED
    
    def select_personality(self, mood: LiveStreamMood) -> VoicePersonality:
        """
        æ ¹æ®æ°›å›´é€‰æ‹©äººæ ¼
        
        å‚æ•°:
            mood: ç›´æ’­é—´æ°›å›´
        
        è¿”å›:
            é€‰æ‹©çš„äººæ ¼
        """
        # æ°›å›´-äººæ ¼æ˜ å°„
        mood_personality_map = {
            LiveStreamMood.EXCITING: VoicePersonality.ENTHUSIASTIC,
            LiveStreamMood.RELAXED: VoicePersonality.CARING,
            LiveStreamMood.INTENSE: VoicePersonality.WITTY,
            LiveStreamMood.WARM: VoicePersonality.CARING,
            LiveStreamMood.SERIOUS: VoicePersonality.PROFESSIONAL
        }
        
        return mood_personality_map.get(mood, self.default_personality)
    
    def transform_response(
        self,
        response: str,
        personality: VoicePersonality = None
    ) -> str:
        """
        æ ¹æ®äººæ ¼è½¬æ¢å›å¤è¯æœ¯
        
        å‚æ•°:
            response: åŸå§‹å›å¤
            personality: äººæ ¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰äººæ ¼ï¼‰
        
        è¿”å›:
            è½¬æ¢åçš„è¯æœ¯
        """
        if personality is None:
            personality = self.current_personality
        
        # æ ¹æ®äººæ ¼æ·»åŠ è¯­æ°”è¯å’Œè¡¨æƒ…
        style_additions = {
            VoicePersonality.PROFESSIONAL: {
                "prefix": "",
                "suffix": "",
                "connectors": ["é¦–å…ˆ", "å…¶æ¬¡", "å¦å¤–"]
            },
            VoicePersonality.ENTHUSIASTIC: {
                "prefix": "å“‡ï¼Œ",
                "suffix": "ï¼å¤ªæ£’äº†ï¼",
                "connectors": ["è€Œä¸”", "å†åŠ ä¸Š", "è¿˜æœ‰å“¦"]
            },
            VoicePersonality.CARING: {
                "prefix": "",
                "suffix": "å‘¢~",
                "connectors": ["è€Œä¸”å‘¢", "å¦å¤–", "è¿˜æœ‰"]
            },
            VoicePersonality.WITTY: {
                "prefix": "",
                "suffix": "å“ˆ~",
                "connectors": ["è¯è¯´", "å¯¹äº†", "é¡ºä¾¿è¯´"]
            },
            VoicePersonality.CALM: {
                "prefix": "",
                "suffix": "ã€‚",
                "connectors": ["é¦–å…ˆ", "å…¶æ¬¡", "æ­¤å¤–"]
            }
        }
        
        additions = style_additions.get(personality, style_additions[self.default_personality])
        
        # å¦‚æœæ˜¯çŸ­å›å¤ï¼Œç›´æ¥æ·»åŠ å‰åç¼€
        if len(response) < 50:
            return f"{additions['prefix']}{response}{additions['suffix']}"
        
        # é•¿å›å¤ï¼Œä¿æŒåŸæ ·ï¼ˆç”±LLMç”Ÿæˆæ—¶å·²ç»è€ƒè™‘äººæ ¼ï¼‰
        return response
    
    def get_voice_config(self, personality: VoicePersonality = None) -> VoiceConfig:
        """
        è·å–äººæ ¼å¯¹åº”çš„è¯­éŸ³é…ç½®
        
        å‚æ•°:
            personality: äººæ ¼
        
        è¿”å›:
            è¯­éŸ³é…ç½®
        """
        if personality is None:
            personality = self.current_personality
        
        return PERSONALITY_CONFIGS.get(personality, PERSONALITY_CONFIGS[self.default_personality])


class TTSVoiceOutput:
    """TTSè¯­éŸ³è¾“å‡º"""
    
    def __init__(self):
        self.tts_client = TTSClient(ctx=new_context(method="tts_output"))
        self.personality_engine = PersonalityEngine()
        self.total_outputs = 0
        self.total_duration = 0
    
    async def synthesize_response(
        self,
        text: str,
        personality: VoicePersonality = None,
        output_format: str = "mp3",
        save_to_file: bool = False,
        output_path: str = None
    ) -> Dict[str, Any]:
        """
        å°†å›å¤åˆæˆä¸ºè¯­éŸ³
        
        å‚æ•°:
            text: å›å¤æ–‡æœ¬
            personality: äººæ ¼ï¼ˆå¯é€‰ï¼‰
            output_format: è¾“å‡ºæ ¼å¼ï¼ˆmp3/pcm/ogg_opusï¼‰
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«éŸ³é¢‘URLå’Œä¿¡æ¯çš„å­—å…¸
        """
        try:
            # è·å–è¯­éŸ³é…ç½®
            voice_config = self.personality_engine.get_voice_config(personality)
            
            # è½¬æ¢è¯æœ¯
            styled_text = self.personality_engine.transform_response(text, personality)
            
            logger.info(f"ğŸ”Š åˆæˆè¯­éŸ³: äººæ ¼={personality.value if personality else 'default'}")
            
            # è°ƒç”¨TTS
            audio_url, audio_size = self.tts_client.synthesize(
                uid=f"live_ai_{int(time.time())}",
                text=styled_text,
                speaker=voice_config.speaker,
                audio_format=output_format,
                sample_rate=24000,
                speech_rate=voice_config.speech_rate,
                loudness_rate=voice_config.loudness_rate
            )
            
            self.total_outputs += 1
            
            result = {
                "success": True,
                "audio_url": audio_url,
                "audio_size": audio_size,
                "text": styled_text,
                "personality": personality.value if personality else "default",
                "format": output_format
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            if save_to_file:
                import requests
                
                audio_data = requests.get(audio_url).content
                
                if output_path is None:
                    output_path = f"/tmp/tts_output_{int(time.time())}.{output_format}"
                
                with open(output_path, 'wb') as f:
                    f.write(audio_data)
                
                result["local_path"] = output_path
                logger.info(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_path}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ TTSåˆæˆå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def synthesize_batch(
        self,
        texts: List[str],
        personality: VoicePersonality = None
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆæˆè¯­éŸ³
        
        å‚æ•°:
            texts: æ–‡æœ¬åˆ—è¡¨
            personality: äººæ ¼
        
        è¿”å›:
            ç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, text in enumerate(texts, 1):
            logger.info(f"ğŸ”Š æ‰¹é‡åˆæˆ {i}/{len(texts)}")
            
            result = await self.synthesize_response(
                text=text,
                personality=personality,
                save_to_file=True,
                output_path=f"/tmp/tts_batch_{i}.mp3"
            )
            
            results.append(result)
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.5)
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_outputs": self.total_outputs,
            "total_duration": self.total_duration
        }


# å…¨å±€å®ä¾‹
tts_output = TTSVoiceOutput()
personality_engine = PersonalityEngine()


def get_voice_output() -> TTSVoiceOutput:
    """è·å–TTSè¾“å‡ºå®ä¾‹"""
    return tts_output


def get_personality_engine() -> PersonalityEngine:
    """è·å–äººæ ¼å¼•æ“å®ä¾‹"""
    return personality_engine


# ä¾¿æ·å‡½æ•°
async def speak(text: str, personality: VoicePersonality = None) -> Dict[str, Any]:
    """
    å¿«æ·è¯­éŸ³åˆæˆå‡½æ•°
    
    å‚æ•°:
        text: è¦åˆæˆçš„æ–‡æœ¬
        personality: äººæ ¼
    
    è¿”å›:
        åˆæˆç»“æœ
    """
    return await tts_output.synthesize_response(text, personality)
