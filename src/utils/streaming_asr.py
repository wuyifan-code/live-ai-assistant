"""
æµå¼ASRè¯­éŸ³è¯†åˆ«
å®æ—¶å°†éŸ³é¢‘æµè½¬æ¢ä¸ºæ–‡æœ¬ï¼Œé™ä½å»¶è¿Ÿåˆ°3-5ç§’
"""

import asyncio
import logging
import queue
import time
from typing import Optional, Callable, Dict, Any
from collections import deque
from coze_coding_dev_sdk import ASRClient
from coze_coding_utils.runtime_ctx.context import new_context
import base64

logger = logging.getLogger(__name__)


class StreamingASR:
    """æµå¼ASRè¯†åˆ«å™¨"""
    
    def __init__(
        self,
        chunk_duration: float = 2.0,
        overlap: float = 0.5,
        sample_rate: int = 16000,
        on_result_callback: Optional[Callable] = None
    ):
        """
        å‚æ•°:
            chunk_duration: éŸ³é¢‘ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
            overlap: é‡å æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºæé«˜è¿ç»­æ€§
            sample_rate: é‡‡æ ·ç‡
            on_result_callback: ç»“æœå›è°ƒå‡½æ•°
        """
        self.chunk_duration = chunk_duration
        self.overlap = overlap
        self.sample_rate = sample_rate
        self.on_result_callback = on_result_callback
        
        self.asr_client = ASRClient(ctx=new_context(method="streaming_asr"))
        self.audio_queue = asyncio.Queue()
        self.is_running = False
        self.last_result = ""
        self.total_processed = 0
    
    async def add_audio_chunk(self, audio_data: bytes):
        """
        æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°é˜Ÿåˆ—
        
        å‚æ•°:
            audio_data: PCMæ ¼å¼éŸ³é¢‘æ•°æ®ï¼ˆ16-bit, monoï¼‰
        """
        await self.audio_queue.put(audio_data)
        logger.debug(f"æ·»åŠ éŸ³é¢‘ç‰‡æ®µ: {len(audio_data)} bytes")
    
    async def start(self):
        """å¯åŠ¨æµå¼è¯†åˆ«"""
        self.is_running = True
        logger.info("ğŸ™ï¸ å¯åŠ¨æµå¼ASRè¯†åˆ«...")
        
        # å¯åŠ¨å¤„ç†ä»»åŠ¡
        processing_task = asyncio.create_task(self._process_audio_loop())
        
        return processing_task
    
    async def _process_audio_loop(self):
        """å¤„ç†éŸ³é¢‘å¾ªç¯"""
        buffer = deque()
        chunk_size = int(self.chunk_duration * self.sample_rate * 2)  # 16-bit = 2 bytes
        overlap_size = int(self.overlap * self.sample_rate * 2)
        
        logger.info(f"éŸ³é¢‘ç‰‡æ®µå¤§å°: {chunk_size} bytes, é‡å : {overlap_size} bytes")
        
        while self.is_running:
            try:
                # è·å–éŸ³é¢‘æ•°æ®
                audio_data = await asyncio.wait_for(
                    self.audio_queue.get(),
                    timeout=1.0
                )
                
                # æ·»åŠ åˆ°ç¼“å†²åŒº
                buffer.extend(audio_data)
                
                # å½“ç¼“å†²åŒºè¶³å¤Ÿå¤§æ—¶ï¼Œè¿›è¡Œå¤„ç†
                while len(buffer) >= chunk_size:
                    # æå–ç‰‡æ®µ
                    chunk = list(buffer)[:chunk_size]
                    del buffer[:chunk_size - overlap_size]  # ä¿ç•™é‡å éƒ¨åˆ†
                    
                    # è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
                    chunk_bytes = bytes(chunk)
                    
                    # è¯†åˆ«è¯­éŸ³
                    await self._recognize_chunk(chunk_bytes)
            
            except asyncio.TimeoutError:
                # æ²¡æœ‰æ–°éŸ³é¢‘ï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"âŒ å¤„ç†éŸ³é¢‘å¤±è´¥: {str(e)}")
                await asyncio.sleep(0.1)
    
    async def _recognize_chunk(self, audio_data: bytes):
        """è¯†åˆ«å•ä¸ªéŸ³é¢‘ç‰‡æ®µ"""
        try:
            # è½¬æ¢ä¸ºbase64
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            # è°ƒç”¨ASR
            start_time = time.time()
            text, data = self.asr_client.recognize(
                uid="streaming_asr",
                base64_data=audio_base64
            )
            processing_time = time.time() - start_time
            
            self.total_processed += 1
            
            if text and text != self.last_result:
                logger.info(
                    f"ğŸ“ è¯†åˆ«ç»“æœ (#{self.total_processed}): {text} "
                    f"(å¤„ç†æ—¶é—´: {processing_time:.2f}s)"
                )
                
                self.last_result = text
                
                # è°ƒç”¨å›è°ƒå‡½æ•°
                if self.on_result_callback:
                    await self.on_result_callback(text, processing_time)
        
        except Exception as e:
            logger.error(f"âŒ ASRè¯†åˆ«å¤±è´¥: {str(e)}")
    
    async def stop(self):
        """åœæ­¢è¯†åˆ«"""
        self.is_running = False
        logger.info("â¹ï¸ æµå¼ASRå·²åœæ­¢")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_processed": self.total_processed,
            "queue_size": self.audio_queue.qsize(),
            "last_result": self.last_result,
            "is_running": self.is_running
        }


class SlidingWindowASR(StreamingASR):
    """æ»‘åŠ¨çª—å£ASR - æé«˜è¿ç»­æ€§å’Œå‡†ç¡®æ€§"""
    
    def __init__(
        self,
        chunk_duration: float = 2.0,
        overlap: float = 0.5,
        sample_rate: int = 16000,
        window_size: int = 3,  # çª—å£å¤§å°ï¼ˆç‰‡æ®µæ•°ï¼‰
        on_result_callback: Optional[Callable] = None
    ):
        super().__init__(chunk_duration, overlap, sample_rate, on_result_callback)
        self.window_size = window_size
        self.results_window = deque(maxlen=window_size)
    
    async def _recognize_chunk(self, audio_data: bytes):
        """è¯†åˆ«éŸ³é¢‘ç‰‡æ®µå¹¶åº”ç”¨æ»‘åŠ¨çª—å£"""
        try:
            # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è¿›è¡Œè¯†åˆ«
            await super()._recognize_chunk(audio_data)
            
            # æ·»åŠ ç»“æœåˆ°çª—å£
            if self.last_result:
                self.results_window.append(self.last_result)
            
            # å¦‚æœçª—å£å·²æ»¡ï¼Œè¿›è¡Œæ–‡æœ¬èåˆ
            if len(self.results_window) >= self.window_size:
                fused_text = self._fuse_results(list(self.results_window))
                
                logger.info(f"ğŸ”— èåˆç»“æœ: {fused_text}")
                
                # è°ƒç”¨å›è°ƒå‡½æ•°
                if self.on_result_callback:
                    await self.on_result_callback(fused_text, 0)
        except Exception as e:
            logger.error(f"âŒ æµå¼è¯†åˆ«å¤±è´¥: {str(e)}")
            if self.on_error_callback:
                await self.on_error_callback(e)
    
    def _fuse_results(self, results: list) -> str:
        """èåˆå¤šä¸ªè¯†åˆ«ç»“æœ"""
        # ç®€å•çš„èåˆç­–ç•¥ï¼šå–æœ€æ–°ç»“æœ
        # å¯ä»¥æ”¹è¿›ä¸ºï¼šå»é‡ã€åˆå¹¶ç›¸ä¼¼å†…å®¹ç­‰
        return results[-1]


class RealtimeAnchorMonitor:
    """å®æ—¶ä¸»æ’­ç›‘æ§å™¨ - ç»“åˆASRå’ŒAIåˆ†æ"""
    
    def __init__(
        self,
        streaming_asr: StreamingASR,
        verify_callback: Optional[Callable] = None
    ):
        """
        å‚æ•°:
            streaming_asr: æµå¼ASRå®ä¾‹
            verify_callback: éªŒè¯å›è°ƒå‡½æ•°
        """
        self.asr = streaming_asr
        self.verify_callback = verify_callback
        self.recent_speeches = deque(maxlen=10)
        self.start_time = time.time()
    
    async def on_speech_result(self, text: str, processing_time: float):
        """
        è¯­éŸ³è¯†åˆ«ç»“æœå›è°ƒ
        
        å‚æ•°:
            text: è¯†åˆ«çš„æ–‡æœ¬
            processing_time: å¤„ç†æ—¶é—´
        """
        # è®°å½•è¯­éŸ³
        speech_entry = {
            "text": text,
            "timestamp": time.time(),
            "processing_time": processing_time,
            "total_latency": time.time() - self.start_time
        }
        
        self.recent_speeches.append(speech_entry)
        
        logger.info(
            f"ğŸ™ï¸ ä¸»æ’­è¯­éŸ³: {text} "
            f"(æ€»å»¶è¿Ÿ: {speech_entry['total_latency']:.2f}s)"
        )
        
        # è°ƒç”¨éªŒè¯å›è°ƒ
        if self.verify_callback:
            await self.verify_callback(text)
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§"""
        logger.info("ğŸ” å¯åŠ¨ä¸»æ’­å®æ—¶ç›‘æ§...")
        
        # è®¾ç½®ASRå›è°ƒ
        self.asr.on_result_callback = self.on_speech_result
        
        # å¯åŠ¨ASR
        await self.asr.start()
    
    async def stop(self):
        """åœæ­¢ç›‘æ§"""
        await self.asr.stop()
        logger.info("â¹ï¸ ä¸»æ’­ç›‘æ§å·²åœæ­¢")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "asr_stats": self.asr.get_stats(),
            "recent_speeches_count": len(self.recent_speeches),
            "avg_processing_time": sum(
                s['processing_time'] for s in self.recent_speeches
            ) / len(self.recent_speeches) if self.recent_speeches else 0,
            "avg_total_latency": sum(
                s['total_latency'] for s in self.recent_speeches
            ) / len(self.recent_speeches) if self.recent_speeches else 0
        }


async def test_streaming_asr():
    """æµ‹è¯•æµå¼ASR"""
    import numpy as np
    
    # åˆ›å»ºæµå¼ASR
    asr = StreamingASR(chunk_duration=2.0, overlap=0.5)
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = RealtimeAnchorMonitor(asr)
    
    # æ¨¡æ‹ŸéŸ³é¢‘æµï¼ˆç”Ÿæˆæµ‹è¯•éŸ³é¢‘ï¼‰
    def simulate_audio_stream():
        """æ¨¡æ‹ŸéŸ³é¢‘æµ"""
        while True:
            # ç”Ÿæˆ2ç§’çš„æµ‹è¯•éŸ³é¢‘ï¼ˆ16kHz, 16-bit, monoï¼‰
            duration = 2.0
            sample_rate = 16000
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            audio = (np.sin(2 * np.pi * 440 * t) * 32767).astype(np.int16)
            audio_bytes = audio.tobytes()
            
            yield audio_bytes
            time.sleep(2.0)
    
    # å¯åŠ¨ç›‘æ§
    monitor_task = await monitor.start()
    
    # æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥
    audio_stream = simulate_audio_stream()
    
    try:
        for i, audio_chunk in enumerate(audio_stream):
            if i >= 3:  # åªæµ‹è¯•3ä¸ªç‰‡æ®µ
                break
            await monitor.asr.add_audio_chunk(audio_chunk)
            await asyncio.sleep(1)
    
    finally:
        await monitor.stop()
        
        # æ‰“å°ç»Ÿè®¡
        stats = monitor.get_stats()
        print("\nğŸ“Š ç›‘æ§ç»Ÿè®¡:")
        print(f"  æ€»å»¶è¿Ÿ: {stats['avg_total_latency']:.2f}s")
        print(f"  å¤„ç†æ—¶é—´: {stats['avg_processing_time']:.2f}s")
        print(f"  è¯†åˆ«ç‰‡æ®µæ•°: {stats['asr_stats']['total_processed']}")


if __name__ == "__main__":
    asyncio.run(test_streaming_asr())
